{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NormLorenz/ai-llm-youtube-transcription-utility/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaBq7A-OcMT5"
      },
      "source": [
        "# Convert the YouTube Transaction Utility\n",
        "## to run Google Colab in anticaption of using AI to:\n",
        "* correct noun casing\n",
        "* correct sentence ending - either a period, a question mark or a exclamation mark\n",
        "* correct beginning of sentence casing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install openai python-dotenv google-generativeai anthropic gradio outube_transcript_api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"All good\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "# from flask import Flask, request, render_template\n",
        "from app import utilities\n",
        "# from config import Config\n",
        "\n",
        "import os\n",
        "import io\n",
        "import sys\n",
        "import json\n",
        "import requests\n",
        "from openai import OpenAI\n",
        "import google.generativeai\n",
        "import anthropic\n",
        "from IPython.display import Markdown, display, update_display\n",
        "import gradio as gr\n",
        "import subprocess\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# keys\n",
        "\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "claude_api_key = userdata.get(\"ANTHROPIC_API_KEY\")\n",
        "google_api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "hugging_face_token = userdata.get(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize\n",
        "\n",
        "openai = OpenAI(api_key=openai_api_key)\n",
        "claude = anthropic.Anthropic(api_key=claude_api_key)\n",
        "google.generativeai.configure(api_key=google_api_key)\n",
        "\n",
        "OPENAI_MODEL = \"gpt-4o-mini\"\n",
        "CLAUDE_MODEL = \"claude-3-5-haiku-latest\"\n",
        "GOOGLE_MODEL = \"gemini-2.5-flash-lite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"You are a Python code assistant. Your task is to analyze Python code and generate high-quality, concise comments and docstrings. Follow these guidelines:\"\n",
        "system_message += \"Docstrings: Add a docstring for every function, class, and module. Describe the purpose of the function/class, its parameters, and its return value. Keep the description concise but informative, using proper Python docstring conventions (e.g., Google, NumPy, or reStructuredText format).\"\n",
        "system_message += \"Inline Comments: Add inline comments only where necessary to clarify complex logic, important steps, or non-obvious behavior. Avoid commenting on obvious operations like x += 1 unless it involves a nuanced concept. Keep comments short, clear, and relevant.\"\n",
        "system_message += \"Typing: Strongly type all variables, arguments, classes, functions and modules.\"\n",
        "system_message += \"General Instructions: Maintain consistency in style and tone. Use technical terminology where appropriate, but ensure clarity for someone with intermediate Python knowledge. Do not over-explain or add redundant comments for self-explanatory code. Follow PEP 257 and PEP 8 standards for style and formatting.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def user_prompt_for(python):\n",
        "    user_prompt = \"Analyze the following Python code and enhance it by adding high-quality, concise docstrings and comments. \"\n",
        "    user_prompt += \"Ensure all functions, classes, and modules have appropriate docstrings describing their purpose, parameters, and return values. \"\n",
        "    user_prompt += \"Add inline comments only for complex or non-obvious parts of the code. \"\n",
        "    user_prompt += \"Follow Python's PEP 257 and PEP 8 standards for documentation and formatting. \"\n",
        "    user_prompt += \"Do not modify the code itself; only add annotations.\\n\\n\"\n",
        "    user_prompt += python\n",
        "    return user_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def messages_for(python):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pi = \"\"\"\n",
        "import time\n",
        "\n",
        "def calculate(iterations, param1, param2):\n",
        "    result = 1.0\n",
        "    for i in range(1, iterations+1):\n",
        "        j = i * param1 - param2\n",
        "        result -= (1/j)\n",
        "        j = i * param1 + param2\n",
        "        result += (1/j)\n",
        "    return result\n",
        "\n",
        "start_time = time.time()\n",
        "result = calculate(100_000_000, 4, 1) * 4\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Result: {result:.12f}\")\n",
        "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_gpt(python):\n",
        "    print(\"stream_gpt\")\n",
        "    stream = openai.chat.completions.create(model=OPENAI_MODEL, messages=messages_for(python), stream=True)\n",
        "    reply = \"\"\n",
        "    for chunk in stream:\n",
        "        fragment = chunk.choices[0].delta.content or \"\"\n",
        "        reply += fragment\n",
        "        yield reply.replace('```python\\n','').replace('```','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_claude(python):\n",
        "    print(\"stream_claude\")\n",
        "    result = claude.messages.stream(\n",
        "        model=CLAUDE_MODEL,\n",
        "        max_tokens=2000,\n",
        "        system=system_message,\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt_for(python)}],\n",
        "    )\n",
        "    reply = \"\"\n",
        "    with result as stream:\n",
        "        for text in stream.text_stream:\n",
        "            reply += text\n",
        "            yield reply.replace('```python\\n','').replace('```','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_google(python):\n",
        "    print(\"stream_google\")\n",
        "    # Initialize empty reply string\n",
        "    reply = \"\"\n",
        "\n",
        "    # The API for Gemini has a slightly different structure\n",
        "    gemini = google.generativeai.GenerativeModel(\n",
        "        model_name=GOOGLE_MODEL,\n",
        "        system_instruction=system_message\n",
        "    )\n",
        "\n",
        "    response = gemini.generate_content(\n",
        "        user_prompt_for(python),\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    # Process the stream\n",
        "    for chunk in response:\n",
        "        # Extract text from the chunk\n",
        "        if chunk.text:\n",
        "            reply += chunk.text\n",
        "            yield reply.replace('```python\\n','').replace('```','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def optimize(python, model):\n",
        "    if model==\"GPT\":\n",
        "        result = stream_gpt(python)\n",
        "    elif model==\"Claude\":\n",
        "        result = stream_claude(python)\n",
        "    elif model==\"Gemini\":\n",
        "        result = stream_google(python)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model\")\n",
        "    for stream_so_far in result:\n",
        "        yield stream_so_far"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def execute_python(code):\n",
        "        try:\n",
        "            output = io.StringIO()\n",
        "            sys.stdout = output\n",
        "            exec(code)\n",
        "        finally:\n",
        "            sys.stdout = sys.__stdout__\n",
        "        return output.getvalue()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "css = \"\"\"\n",
        ".python {background-color: #306998;}\n",
        ".cpp {background-color: #050;}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with gr.Blocks(css=css) as ui:\n",
        "    gr.Markdown(\"## Comment and Type Provided Python Code\")\n",
        "    with gr.Row():\n",
        "        python = gr.Textbox(label=\"Python code:\", value=pi, lines=10)\n",
        "        commented_python = gr.Textbox(label=\"Commented and Typed code:\", lines=10)\n",
        "    with gr.Row():\n",
        "        model = gr.Dropdown([\"GPT\", \"Claude\", \"Gemini\"], label=\"Select model\", value=\"GPT\")\n",
        "    with gr.Row():\n",
        "        comment = gr.Button(\"Comment and Type code\")\n",
        "    with gr.Row():\n",
        "        python_run = gr.Button(\"Check Commented Python\")\n",
        "    with gr.Row():\n",
        "        python_out = gr.TextArea(label=\"Python result:\", elem_classes=[\"python\"])\n",
        "\n",
        "    comment.click(optimize, inputs=[python, model], outputs=[commented_python])\n",
        "    python_run.click(execute_python, inputs=[python], outputs=[python_out])\n",
        "\n",
        "ui.launch(inbrowser=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPlCTMsluILuZQbPQazi58e",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai-llm-youtube-transcription-utility",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

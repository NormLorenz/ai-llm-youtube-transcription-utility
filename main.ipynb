{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NormLorenz/ai-llm-youtube-transcription-utility/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaBq7A-OcMT5"
      },
      "source": [
        "# Convert the YouTube Transaction Utility\n",
        "## Run in Google Colab in anticipation of using AI to:\n",
        "* correct noun casing\n",
        "* correct sentence ending - either a period, a question mark or a exclamation mark\n",
        "* correct beginning of sentence casing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installs\n",
        "\n",
        "!pip install openai python-dotenv google-generativeai anthropic gradio youtube_transcript_api"
      ],
      "metadata": {
        "id": "qW9x6HD3ltaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld05Mscy873Y"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import io\n",
        "import sys\n",
        "import json\n",
        "import requests\n",
        "from openai import OpenAI\n",
        "import google.generativeai\n",
        "import anthropic\n",
        "from IPython.display import Markdown, display, update_display\n",
        "import gradio as gr\n",
        "import subprocess\n",
        "from google.colab import userdata\n",
        "from typing import Dict, List, Union\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the utilities module from github\n",
        "\n",
        "%%bash\n",
        "wget https://raw.githubusercontent.com/NormLorenz/ai-llm-youtube-transcription-utility/refs/heads/main/utilities.py\n",
        "wget https://raw.githubusercontent.com/NormLorenz/ai-llm-youtube-transcription-utility/refs/heads/main/README.md"
      ],
      "metadata": {
        "id": "MefIb11pw0AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add /content to the Python path to allow importing local modules.\n",
        "# this ensures that Python can find 'utilities.py' as a module.\n",
        "sys.path.append('/content')\n",
        "\n",
        "# list content of /content for verification (optional).\n",
        "display(os.listdir('/content'))\n",
        "\n",
        "# import utilities.py\n",
        "import utilities"
      ],
      "metadata": {
        "id": "Ak_BtUlpOW-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl8p4NQq873Z"
      },
      "outputs": [],
      "source": [
        "# keys\n",
        "\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "claude_api_key = userdata.get(\"ANTHROPIC_API_KEY\")\n",
        "google_api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "hugging_face_token = userdata.get(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgOjs8HH873a"
      },
      "outputs": [],
      "source": [
        "# initialize\n",
        "\n",
        "openai = OpenAI(api_key=openai_api_key)\n",
        "claude = anthropic.Anthropic(api_key=claude_api_key)\n",
        "google.generativeai.configure(api_key=google_api_key)\n",
        "\n",
        "OPENAI_MODEL = \"gpt-4o-mini\"\n",
        "CLAUDE_MODEL = \"claude-3-5-haiku-latest\"\n",
        "GOOGLE_MODEL = \"gemini-2.5-flash-lite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ6t98wh873b"
      },
      "outputs": [],
      "source": [
        "# create a system message\n",
        "\n",
        "system_message = \"You are a Python code assistant. Your task is to analyze Python code and generate high-quality, concise comments and docstrings. Follow these guidelines:\"\n",
        "system_message += \"Docstrings: Add a docstring for every function, class, and module. Describe the purpose of the function/class, its parameters, and its return value. Keep the description concise but informative, using proper Python docstring conventions (e.g., Google, NumPy, or reStructuredText format).\"\n",
        "system_message += \"Inline Comments: Add inline comments only where necessary to clarify complex logic, important steps, or non-obvious behavior. Avoid commenting on obvious operations like x += 1 unless it involves a nuanced concept. Keep comments short, clear, and relevant.\"\n",
        "system_message += \"Typing: Strongly type all variables, arguments, classes, functions and modules.\"\n",
        "system_message += \"General Instructions: Maintain consistency in style and tone. Use technical terminology where appropriate, but ensure clarity for someone with intermediate Python knowledge. Do not over-explain or add redundant comments for self-explanatory code. Follow PEP 257 and PEP 8 standards for style and formatting.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHzjBmJR873c"
      },
      "outputs": [],
      "source": [
        "# create a user prompt\n",
        "\n",
        "def user_prompt_for(python):\n",
        "    user_prompt = \"Analyze the following Python code and enhance it by adding high-quality, concise docstrings and comments. \"\n",
        "    user_prompt += \"Ensure all functions, classes, and modules have appropriate docstrings describing their purpose, parameters, and return values. \"\n",
        "    user_prompt += \"Add inline comments only for complex or non-obvious parts of the code. \"\n",
        "    user_prompt += \"Follow Python's PEP 257 and PEP 8 standards for documentation and formatting. \"\n",
        "    user_prompt += \"Do not modify the code itself; only add annotations.\\n\\n\"\n",
        "    user_prompt += python\n",
        "    return user_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIniOxr1873c"
      },
      "outputs": [],
      "source": [
        "# create a list of dictionaries for the mod\n",
        "\n",
        "def messages_for(python):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8R0i-su873d"
      },
      "outputs": [],
      "source": [
        "pi = \"\"\"\n",
        "import time\n",
        "\n",
        "def calculate(iterations, param1, param2):\n",
        "    result = 1.0\n",
        "    for i in range(1, iterations+1):\n",
        "        j = i * param1 - param2\n",
        "        result -= (1/j)\n",
        "        j = i * param1 + param2\n",
        "        result += (1/j)\n",
        "    return result\n",
        "\n",
        "start_time = time.time()\n",
        "result = calculate(100_000_000, 4, 1) * 4\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Result: {result:.12f}\")\n",
        "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFBEjcou873d"
      },
      "outputs": [],
      "source": [
        "def stream_gpt(python):\n",
        "    stream = openai.chat.completions.create(model=OPENAI_MODEL, messages=messages_for(python), stream=True)\n",
        "    reply = \"\"\n",
        "    for chunk in stream:\n",
        "        fragment = chunk.choices[0].delta.content or \"\"\n",
        "        reply += fragment\n",
        "        yield reply.replace('```python\\n','').replace('```','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWhwra84873d"
      },
      "outputs": [],
      "source": [
        "def stream_claude(python):\n",
        "    result = claude.messages.stream(\n",
        "        model=CLAUDE_MODEL,\n",
        "        max_tokens=2000,\n",
        "        system=system_message,\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt_for(python)}],\n",
        "    )\n",
        "    reply = \"\"\n",
        "    with result as stream:\n",
        "        for text in stream.text_stream:\n",
        "            reply += text\n",
        "            yield reply.replace('```python\\n','').replace('```','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzZUT8r_873e"
      },
      "outputs": [],
      "source": [
        "def stream_google(python):\n",
        "    reply = \"\"\n",
        "    gemini = google.generativeai.GenerativeModel(\n",
        "        model_name=GOOGLE_MODEL,\n",
        "        system_instruction=system_message\n",
        "    )\n",
        "    response = gemini.generate_content(\n",
        "        user_prompt_for(python),\n",
        "        stream=True\n",
        "    )\n",
        "    for chunk in response:\n",
        "        if chunk.text:\n",
        "            reply += chunk.text\n",
        "            yield reply.replace('```python\\n','').replace('```','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdFGTJCL873e"
      },
      "outputs": [],
      "source": [
        "def optimize(python, model):\n",
        "    if model==\"GPT\":\n",
        "        result = stream_gpt(python)\n",
        "    elif model==\"Claude\":\n",
        "        result = stream_claude(python)\n",
        "    elif model==\"Gemini\":\n",
        "        result = stream_google(python)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model\")\n",
        "    for stream_so_far in result:\n",
        "        yield stream_so_far"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxw2O_xQ873e"
      },
      "outputs": [],
      "source": [
        "def execute_python(code):\n",
        "        try:\n",
        "            output = io.StringIO()\n",
        "            sys.stdout = output\n",
        "            exec(code)\n",
        "        finally:\n",
        "            sys.stdout = sys.__stdout__\n",
        "        return output.getvalue()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEWO-f_O873f"
      },
      "outputs": [],
      "source": [
        "css = \"\"\"\n",
        ".python {background-color: #306998;}\n",
        ".cpp {background-color: #050;}\n",
        ".table {background-color: red;}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "youTubeURL = \"https://www.youtube.com/watch?v=L6HnBjnkKmM\""
      ],
      "metadata": {
        "id": "w1Y-lQonHhFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3ReogCUGEsu"
      },
      "outputs": [],
      "source": [
        "# gradio ui\n",
        "\n",
        "from typing import List, Dict\n",
        "import gradio as gr\n",
        "\n",
        "# JavaScript function to copy content from the displayed table\n",
        "copy_js = \"\"\"\n",
        "function() {\n",
        "    const table = document.querySelector('table');\n",
        "    const range = document.createRange();\n",
        "    range.selectNode(table);\n",
        "    window.getSelection().removeAllRanges();\n",
        "    window.getSelection().addRange(range);\n",
        "    document.execCommand('copy');\n",
        "    alert('Table copied to clipboard!');\n",
        "    return [];\n",
        "    }\n",
        "\"\"\"\n",
        "\n",
        "def clear_fields():\n",
        "    return [None, \"\"]\n",
        "\n",
        "def generate_transcript(url: str) -> List[Dict[str, str]]:\n",
        "   return [\n",
        "    {\"start\": \"00:31\", \"text\": \"Wie geht's dir?\"},\n",
        "    {\"start\": \"01:23\", \"text\": \"Ich trinke Kaffee mit Zucher.\"},\n",
        "    {\"start\": \"02:44\", \"text\": \"Hallo!\"},\n",
        "   ]\n",
        "\n",
        "def fetch_transcript(url):\n",
        "    transcript = generate_transcript(url)\n",
        "    # transcript = utilities.get_transcript(url)\n",
        "    html = \"<table>\\n\"\n",
        "    html += \"  <tbody>\\n\"\n",
        "    for item in transcript:\n",
        "        html += f\"    <tr><td>{item['start']}</td><td>{item['text']}</td></tr>\\n\"\n",
        "    html += \"  </tbody>\\n\"\n",
        "    html += \"</table>\"\n",
        "    return (html)\n",
        "\n",
        "with gr.Blocks(css=css) as ui:\n",
        "\n",
        "    gr.Markdown(\"## YouTube Transcript Utility\")\n",
        "    gr.Markdown(\"### Creates a HTML table that can be copied and pasted into a Windows OneNote application\")\n",
        "\n",
        "    with gr.Row():\n",
        "        url = gr.Textbox(label=\"YouTube Video URL:\", value=youTubeURL, lines=1)\n",
        "    with gr.Row():\n",
        "        model = gr.Dropdown([\"GPT\", \"Claude\", \"Gemini\"], label=\"AI Model Name:\", value=\"GPT\")\n",
        "    with gr.Row():\n",
        "        fetch = gr.Button(\"Fetch\", variant=\"primary\")\n",
        "        gr.Button(\"Copy\").click(fn=None, inputs=[], outputs=[], js=copy_js)\n",
        "        clear = gr.Button(\"Clear\")\n",
        "    with gr.Row():\n",
        "        html = gr.HTML()\n",
        "\n",
        "    clear.click(clear_fields, inputs=[], outputs=[url, html])\n",
        "    fetch.click(fetch_transcript, inputs=[url], outputs=[html])\n",
        "\n",
        "ui.launch(inbrowser=True, debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "ai-llm-youtube-transcription-utility",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
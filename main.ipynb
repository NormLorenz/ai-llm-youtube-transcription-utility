{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NormLorenz/ai-llm-youtube-transcription-utility/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaBq7A-OcMT5"
      },
      "source": [
        "# Convert the YouTube Transaction Utility to Colab\n",
        "## Run in Google Colab in anticipation of using AI to:\n",
        "* correct noun casing\n",
        "* correct sentence ending - either a period, a question mark or a exclamation mark\n",
        "* correct word spelling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install and run a code formatter\n",
        "# !pip install jupyter-black\n",
        "# !pip uninstall jupyter-black\n",
        "# %load_ext jupyter_black"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Rr0_pcLvAIGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installs\n",
        "\n",
        "!pip install openai python-dotenv google-generativeai anthropic youtube_transcript_api"
      ],
      "metadata": {
        "id": "qW9x6HD3ltaV",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld05Mscy873Y"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import io\n",
        "import sys\n",
        "import json\n",
        "import requests\n",
        "from openai import OpenAI\n",
        "import google.generativeai\n",
        "import anthropic\n",
        "from IPython.display import Markdown, display, update_display\n",
        "import gradio as gr\n",
        "import subprocess\n",
        "from google.colab import userdata\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import re\n",
        "import pprint\n",
        "from typing import List, Dict, Union, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the utilities module from github\n",
        "\n",
        "%%bash\n",
        "wget https://raw.githubusercontent.com/NormLorenz/ai-llm-youtube-transcription-utility/refs/heads/main/utilities.py\n",
        "wget https://raw.githubusercontent.com/NormLorenz/ai-llm-youtube-transcription-utility/refs/heads/main/README.md"
      ],
      "metadata": {
        "id": "MefIb11pw0AX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add /content to the Python path to allow importing local modules.\n",
        "# this ensures that Python can find 'utilities.py' as a module.\n",
        "sys.path.append(\"/content\")\n",
        "\n",
        "# list content of /content for verification (optional).\n",
        "display(os.listdir(\"/content\"))\n",
        "\n",
        "# verify utilities.py exists before importing\n",
        "utilities_path = os.path.join(\"/content\", \"utilities.py\")\n",
        "if os.path.exists(utilities_path):\n",
        "    import utilities\n",
        "\n",
        "    print(\"utilities.py imported successfully.\")\n",
        "else:\n",
        "    print(\n",
        "        f\"Error: utilities.py not found at {utilities_path}. Please ensure 'wget' in cell MefIb11pw0AX ran successfully.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "Ak_BtUlpOW-P",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl8p4NQq873Z"
      },
      "outputs": [],
      "source": [
        "# keys\n",
        "\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "claude_api_key = userdata.get(\"ANTHROPIC_API_KEY\")\n",
        "google_api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "hugging_face_token = userdata.get(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgOjs8HH873a"
      },
      "outputs": [],
      "source": [
        "# initialize\n",
        "\n",
        "openai = OpenAI(api_key=openai_api_key)\n",
        "claude = anthropic.Anthropic(api_key=claude_api_key)\n",
        "google.generativeai.configure(api_key=google_api_key)\n",
        "\n",
        "OPENAI_MODEL = \"gpt-4o-mini\"\n",
        "CLAUDE_MODEL = \"claude-3-5-haiku-latest\"\n",
        "GOOGLE_MODEL = \"gemini-2.5-flash-lite\"\n",
        "\n",
        "MODELS = [\n",
        "    \"OPENAI (gpt-4)\",\n",
        "    \"OPENAI (gpt-4o-mini)\",\n",
        "    \"ANTHROPIC (claude-3-5-haiku-latest)\",\n",
        "    \"GOOGLE (gemini-2.5-flash-lite)\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ6t98wh873b"
      },
      "outputs": [],
      "source": [
        "def system_message() -> str:\n",
        "    \"\"\"Create a system message.\"\"\"\n",
        "    system_message = \"You are a German language tutor. Your task is to review and correct a Python list of dictionaries that contain \"\n",
        "    system_message += \"a time stamp and a German sentence. The sentence may have incorrect casing for German nouns and may have incorrect \"\n",
        "    system_message += \"or missing period, question mark or exclamation point. Also please correct any casing at the start of the sentence and \"\n",
        "    system_message += \"any misspelled words. The expected output format should be a Python list of dictionaries such as: \"\n",
        "    system_message += '[{\"start\": \"00:01\", \"text\": \"Ich habe ein Buch gelesen.\"}, {\"start\": \"00:05\", \"text\": \"Das ist ein Haus.\"}]'\n",
        "    return system_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHzjBmJR873c"
      },
      "outputs": [],
      "source": [
        "def user_prompt(items: List[Dict[str, str]]):\n",
        "    \"\"\"Create a user prompt.\"\"\"\n",
        "    user_prompt = \"Please review and correct the following: \\n\"\n",
        "    user_prompt += str(items)\n",
        "    return user_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFBEjcou873d"
      },
      "outputs": [],
      "source": [
        "def stream_gpt(items: List[Dict[str, str]]):\n",
        "    \"\"\"Stream an OpenAI response.\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message()},\n",
        "        {\"role\": \"user\", \"content\": user_prompt(items)},\n",
        "    ]\n",
        "    stream = openai.chat.completions.create(\n",
        "        model=OPENAI_MODEL, messages=messages, stream=True\n",
        "    )\n",
        "    reply = \"\"\n",
        "    for chunk in stream:\n",
        "        fragment = chunk.choices[0].delta.content or \"\"\n",
        "        reply += fragment\n",
        "        yield reply.replace(\"```python\\n\", \"\").replace(\"```\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_data = [\n",
        "#     {\"start\": \"00:01\", \"text\": \"ich habe ein buch gelesen\"},\n",
        "#     {\"start\": \"00:05\", \"text\": \"dass ist ein haus\"},\n",
        "#     {\"start\": \"00:10\", \"text\": \"wie geht es dir\"},\n",
        "#     {\"start\": \"00:15\", \"text\": \"seien sie vorsicht\"},\n",
        "# ]\n",
        "\n",
        "# print(\"Calling stream_gpt with sample data...\")\n",
        "# for chunk in stream_gpt(sample_data):\n",
        "#     print(chunk)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FrzIHtvRDIjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWhwra84873d"
      },
      "outputs": [],
      "source": [
        "def stream_claude(items: List[Dict[str, str]]):\n",
        "    \"\"\"Stream a Claude response.\"\"\"\n",
        "    result = claude.messages.stream(\n",
        "        model=CLAUDE_MODEL,\n",
        "        max_tokens=2000,\n",
        "        system=system_message(),\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt(items)}],\n",
        "    )\n",
        "    reply = \"\"\n",
        "    with result as stream:\n",
        "        for text in stream.text_stream:\n",
        "            reply += text\n",
        "            yield reply.replace(\"```python\\n\", \"\").replace(\"```\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_data = [\n",
        "#     {\"start\": \"00:01\", \"text\": \"ich habe ein buch gelesen\"},\n",
        "#     {\"start\": \"00:05\", \"text\": \"dass ist ein haus\"},\n",
        "#     {\"start\": \"00:10\", \"text\": \"wie geht es dir\"},\n",
        "#     {\"start\": \"00:15\", \"text\": \"seien sie vorsicht\"},\n",
        "# ]\n",
        "\n",
        "# print(\"Calling stream_claude with sample data...\")\n",
        "# for chunk in stream_claude(sample_data):\n",
        "#     print(chunk)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8lIACpgjFBpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzZUT8r_873e"
      },
      "outputs": [],
      "source": [
        "def stream_google(items: List[Dict[str, str]]):\n",
        "    \"\"\"Stream a Google response.\"\"\"\n",
        "    reply = \"\"\n",
        "    gemini = google.generativeai.GenerativeModel(\n",
        "        model_name=GOOGLE_MODEL, system_instruction=system_message()\n",
        "    )\n",
        "    response = gemini.generate_content(user_prompt(items), stream=True)\n",
        "    for chunk in response:\n",
        "        if chunk.text:\n",
        "            reply += chunk.text\n",
        "            yield reply.replace(\"```python\\n\", \"\").replace(\"```\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_data = [\n",
        "#     {\"start\": \"00:01\", \"text\": \"ich habe ein buch gelesen\"},\n",
        "#     {\"start\": \"00:05\", \"text\": \"dass ist ein haus\"},\n",
        "#     {\"start\": \"00:10\", \"text\": \"wie geht es dir\"},\n",
        "#     {\"start\": \"00:15\", \"text\": \"seien sie vorsicht\"},\n",
        "# ]\n",
        "\n",
        "# print(\"Calling stream_google with sample data...\")\n",
        "# for chunk in stream_google(sample_data):\n",
        "#     print(chunk)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QFT1R8wbFjq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdFGTJCL873e"
      },
      "outputs": [],
      "source": [
        "def optimize(python, model):\n",
        "    \"\"\"Optimize the generated Python code.\"\"\"\n",
        "    if model == \"GPT\":\n",
        "        result = stream_gpt(python)\n",
        "    elif model == \"Claude\":\n",
        "        result = stream_claude(python)\n",
        "    elif model == \"Gemini\":\n",
        "        result = stream_google(python)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model\")\n",
        "    for stream_so_far in result:\n",
        "        yield stream_so_far"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxw2O_xQ873e"
      },
      "outputs": [],
      "source": [
        "def execute_python(code):\n",
        "    \"\"\"Execute Python code and return the output.\"\"\"\n",
        "    try:\n",
        "        output = io.StringIO()\n",
        "        sys.stdout = output\n",
        "        exec(code)\n",
        "    finally:\n",
        "        sys.stdout = sys.__stdout__\n",
        "    return output.getvalue()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def non_stream_google(model: str, items: List[Dict[str, str]])-> List[Dict[str, str]]:\n",
        "    \"\"\"Generate a non-streaming Google response.\"\"\"\n",
        "    gemini = google.generativeai.GenerativeModel(\n",
        "        model_name=model, system_instruction=system_message()\n",
        "    )\n",
        "    response: str = gemini.generate_content(user_prompt(items), stream=False).text\n",
        "\n",
        "    # Extract the list using regex\n",
        "    match = re.search(r\"\\[.*\\]\", response)\n",
        "    if match:\n",
        "        list_str = match.group(0).replace(\"'\", '\"')\n",
        "        return json.loads(list_str)\n",
        "    else:\n",
        "        return [{\"start\": \"00:00\", \"text\": \"Wasn't able to get a decent response.\"}]"
      ],
      "metadata": {
        "id": "e8-v0V_hS59m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3ReogCUGEsu"
      },
      "outputs": [],
      "source": [
        "\"\"\"Gradio UI for the YouTube Transcript Utility.\"\"\"\n",
        "\n",
        "selected_model: str = \"\"\n",
        "selected_provider: str = \"\"\n",
        "\n",
        "css: str = \"\"\"\n",
        "  #my_html_box { border: 2px solid blue; padding: 10px; }\n",
        "\"\"\"\n",
        "\n",
        "js: str = \"\"\"\n",
        "function() {\n",
        "    const table = document.querySelector('table');\n",
        "    const range = document.createRange();\n",
        "    range.selectNode(table);\n",
        "    window.getSelection().removeAllRanges();\n",
        "    window.getSelection().addRange(range);\n",
        "    document.execCommand('copy');\n",
        "    alert('Table copied to clipboard!');\n",
        "    window.getSelection().removeAllRanges();\n",
        "    return [];\n",
        "    }\n",
        "\"\"\"\n",
        "\n",
        "sample_url: str = (\n",
        "    \"https://www.youtube.com/watch?v=L6HnBjnkKmM&list=PLCCi8icw2DAO1qZGH7heUyTB8bJP1ICZ5&index=28\"\n",
        ")\n",
        "\n",
        "\n",
        "def clear_fields() -> Tuple[None, str, str]:\n",
        "    \"\"\"Clear all fields.\"\"\"\n",
        "    return (None, \"\", \"\")\n",
        "\n",
        "\n",
        "def mock_original_data(url: str) -> List[Dict[str, str]]:\n",
        "    \"\"\"Mock the original transcript data.\"\"\"\n",
        "    return [\n",
        "        {\"start\": \"00:01\", \"text\": \"ich habe ein buch gelesen\"},\n",
        "        {\"start\": \"00:05\", \"text\": \"dass ist ein haus\"},\n",
        "        {\"start\": \"00:10\", \"text\": \"wie geht es dir\"},\n",
        "        {\"start\": \"00:10\", \"text\": \"seien sie vorsicht\"},\n",
        "    ]\n",
        "\n",
        "\n",
        "def mock_corrected_data(url: str) -> List[Dict[str, str]]:\n",
        "    \"\"\"Mock the corrected transcript data.\"\"\"\n",
        "    return [\n",
        "        {\"start\": \"00:01\", \"text\": \"Ich habe ein Buch gelesen.\"},\n",
        "        {\"start\": \"00:05\", \"text\": \"Das ist ein Haus.\"},\n",
        "        {\"start\": \"00:10\", \"text\": \"Wie geht es dir?\"},\n",
        "        {\"start\": \"00:10\", \"text\": \"Seien Sie vorsichtig!\"},\n",
        "    ]\n",
        "\n",
        "\n",
        "def build_table(items: List[Dict[str, str]]) -> str:\n",
        "    \"\"\"Build an HTML table from the list of dictionaries.\"\"\"\n",
        "    html: str = \"<table width=100%>\\n\"\n",
        "    html += \"  <tbody>\\n\"\n",
        "    for item in items:\n",
        "        html += f\"    <tr><td>{item['start']}</td><td>{item['text']}</td></tr>\\n\"\n",
        "    html += \"  </tbody>\\n\"\n",
        "    html += \"</table>\"\n",
        "    return html\n",
        "\n",
        "\n",
        "def build_text(items: List[Dict[str, str]]) -> str:\n",
        "    \"\"\"Build a text string from the list of dictionaries.\"\"\"\n",
        "    return pprint.pformat(items, indent=4)\n",
        "\n",
        "\n",
        "def get_corrected_transcript(model: str, provider: str, items: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
        "    \"\"\"Get the corrected transcript.\"\"\"\n",
        "    response = non_stream_google(model, items)\n",
        "    return response\n",
        "\n",
        "def fetch_transcript(url: str, mock: bool, model: str) -> Tuple[str, str]:\n",
        "    \"\"\"Fetch the transcript.\"\"\"\n",
        "    if not url:\n",
        "        return (\n",
        "            \"\",\n",
        "            \"<p style='color: orange;'>The YouTube Video URL field can't be empty!</p>\",\n",
        "        )\n",
        "    else:\n",
        "        transcript_original: List[Dict[str, str]] = (\n",
        "            mock_original_data(url) if mock else utilities.get_transcript(url)\n",
        "        )\n",
        "        transcript_corrected: List[Dict[str, str]] = (\n",
        "            mock_corrected_data(url)\n",
        "            if mock\n",
        "            else get_corrected_transcript(\n",
        "                selected_model, selected_provider, transcript_original\n",
        "            )\n",
        "        )\n",
        "        list_original: str = build_text(transcript_original)\n",
        "        html_corrected: str = build_table(transcript_corrected)\n",
        "        return list_original, html_corrected\n",
        "\n",
        "\n",
        "def display_model(model: str) -> None:\n",
        "    \"\"\"Display the selected model.\"\"\"\n",
        "    global selected_provider\n",
        "    selected_provider = model.split(\" \")[0]\n",
        "    global selected_model\n",
        "    selected_model = model.split(\" \")[1].replace(\"(\", \"\").replace(\")\", \"\")\n",
        "\n",
        "\n",
        "with gr.Blocks(css=css) as ui:\n",
        "\n",
        "    gr.Markdown(\"## YouTube Transcript Utility\")\n",
        "    gr.Markdown(\"### Creates a HTML table that can be copied and pasted into a Windows OneNote application\")\n",
        "\n",
        "    with gr.Row():\n",
        "        url = gr.Textbox(label=\"YouTube Video URL:\", value=sample_url)\n",
        "    with gr.Row():\n",
        "        model = gr.Dropdown(MODELS, label=\"AI Model Name:\", value=MODELS[3])\n",
        "    with gr.Row():\n",
        "        mock = gr.Checkbox(label=\"Use Mock Data\", value=True)\n",
        "    with gr.Row():\n",
        "        fetch = gr.Button(\"Fetch\", variant=\"primary\")\n",
        "        copy = gr.Button(\"Copy\")\n",
        "        clear = gr.Button(\"Clear\")\n",
        "    with gr.Row():\n",
        "        text = gr.TextArea(label=\"Original Transcript\")\n",
        "        html = gr.HTML(elem_id=\"my_html_box\")\n",
        "\n",
        "    fetch.click(fetch_transcript, inputs=[url, mock, model], outputs=[text, html])\n",
        "    copy.click(fn=None, inputs=[], outputs=[], js=js)\n",
        "    clear.click(clear_fields, inputs=[], outputs=[url, text, html])\n",
        "    model.change(display_model, inputs=[model], outputs=[])\n",
        "\n",
        "    # trigger manually on launch\n",
        "    ui.load(display_model, [model], [])\n",
        "\n",
        "\n",
        "ui.launch(inbrowser=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "ai-llm-youtube-transcription-utility",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
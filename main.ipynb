{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NormLorenz/ai-llm-youtube-transcription-utility/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaBq7A-OcMT5"
      },
      "source": [
        "# Convert the YouTube Transaction Utility to Colab\n",
        "## Run in Google Colab in anticipation of using AI to:\n",
        "* correct noun casing\n",
        "* correct sentence ending - either a period, a question mark or a exclamation mark\n",
        "* correct word spelling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installs\n",
        "\n",
        "!pip install openai python-dotenv google-generativeai anthropic youtube_transcript_api"
      ],
      "metadata": {
        "id": "qW9x6HD3ltaV",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld05Mscy873Y"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import io\n",
        "import sys\n",
        "import json\n",
        "import requests\n",
        "from openai import OpenAI\n",
        "import google.generativeai\n",
        "import anthropic\n",
        "from IPython.display import Markdown, display, update_display\n",
        "import gradio as gr\n",
        "import subprocess\n",
        "from google.colab import userdata\n",
        "from typing import Dict, List, Union\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the utilities module from github\n",
        "\n",
        "%%bash\n",
        "wget https://raw.githubusercontent.com/NormLorenz/ai-llm-youtube-transcription-utility/refs/heads/main/utilities.py\n",
        "wget https://raw.githubusercontent.com/NormLorenz/ai-llm-youtube-transcription-utility/refs/heads/main/README.md"
      ],
      "metadata": {
        "id": "MefIb11pw0AX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add /content to the Python path to allow importing local modules.\n",
        "# this ensures that Python can find 'utilities.py' as a module.\n",
        "sys.path.append('/content')\n",
        "\n",
        "# list content of /content for verification (optional).\n",
        "display(os.listdir('/content'))\n",
        "\n",
        "# import utilities.py\n",
        "import utilities"
      ],
      "metadata": {
        "id": "Ak_BtUlpOW-P",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl8p4NQq873Z"
      },
      "outputs": [],
      "source": [
        "# keys\n",
        "\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "claude_api_key = userdata.get(\"ANTHROPIC_API_KEY\")\n",
        "google_api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "hugging_face_token = userdata.get(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgOjs8HH873a"
      },
      "outputs": [],
      "source": [
        "# initialize\n",
        "\n",
        "openai = OpenAI(api_key=openai_api_key)\n",
        "claude = anthropic.Anthropic(api_key=claude_api_key)\n",
        "google.generativeai.configure(api_key=google_api_key)\n",
        "\n",
        "OPENAI_MODEL = \"gpt-4o-mini\"\n",
        "CLAUDE_MODEL = \"claude-3-5-haiku-latest\"\n",
        "GOOGLE_MODEL = \"gemini-2.5-flash-lite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ6t98wh873b"
      },
      "outputs": [],
      "source": [
        "# create a system message\n",
        "\n",
        "def system_message():\n",
        "    system_message = \"You are a German language tutor. Your task is to review and correct a Python list of dictionaries that contain \"\n",
        "    system_message += \"a time stamp and a German sentence. The sentence may have incorrect casing for German nouns and may have incorrect \"\n",
        "    system_message += \"or missing period, question mark or explanation mark. Also please correct any casing at the start of the sentence and \"\n",
        "    system_message += \"and any misspelled words.\"\n",
        "    return system_message\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHzjBmJR873c"
      },
      "outputs": [],
      "source": [
        "# create a user prompt\n",
        "\n",
        "def user_prompt(items: List[Dict[str, str]]):\n",
        "    user_prompt = \"Please analyze the following and only return a Python list of dictionaries: \\n\"\n",
        "    user_prompt += str(items)\n",
        "    return user_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFBEjcou873d"
      },
      "outputs": [],
      "source": [
        "# stream an openai response\n",
        "\n",
        "def stream_gpt(items: List[Dict[str, str]]):\n",
        "    messages =  [\n",
        "        {\"role\": \"system\", \"content\": system_message()},\n",
        "        {\"role\": \"user\", \"content\": user_prompt(items)}\n",
        "    ]\n",
        "    stream = openai.chat.completions.create(model=OPENAI_MODEL, messages=messages, stream=True)\n",
        "    reply = \"\"\n",
        "    for chunk in stream:\n",
        "        fragment = chunk.choices[0].delta.content or \"\"\n",
        "        reply += fragment\n",
        "        yield reply.replace('```python\\n','').replace('```','')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = [\n",
        "    {\"start\": \"00:01\", \"text\": \"ich habe ein buch gelesen\"},\n",
        "    {\"start\": \"00:05\", \"text\": \"dass ist ein haus\"},\n",
        "    {\"start\": \"00:10\", \"text\": \"wie geht es dir\"}\n",
        "]\n",
        "\n",
        "print(\"Calling stream_gpt with sample data...\")\n",
        "for chunk in stream_gpt(sample_data):\n",
        "    print(chunk)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FrzIHtvRDIjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWhwra84873d"
      },
      "outputs": [],
      "source": [
        "# stream a antrophic response\n",
        "\n",
        "def stream_claude(items: List[Dict[str, str]]):\n",
        "    result = claude.messages.stream(\n",
        "        model=CLAUDE_MODEL,\n",
        "        max_tokens=2000,\n",
        "        system=system_message(),\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt(items)}],\n",
        "    )\n",
        "    reply = \"\"\n",
        "    with result as stream:\n",
        "        for text in stream.text_stream:\n",
        "            reply += text\n",
        "            yield reply.replace('```python\\n','').replace('```','')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = [\n",
        "    {\"start\": \"00:01\", \"text\": \"ich habe ein buch gelesen\"},\n",
        "    {\"start\": \"00:05\", \"text\": \"dass ist ein haus\"},\n",
        "    {\"start\": \"00:10\", \"text\": \"wie geht es dir\"}\n",
        "]\n",
        "\n",
        "print(\"Calling stream_claude with sample data...\")\n",
        "for chunk in stream_claude(sample_data):\n",
        "    print(chunk)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8lIACpgjFBpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzZUT8r_873e"
      },
      "outputs": [],
      "source": [
        "# stream a google response\n",
        "\n",
        "def stream_google(items: List[Dict[str, str]]):\n",
        "    reply = \"\"\n",
        "    gemini = google.generativeai.GenerativeModel(\n",
        "        model_name=GOOGLE_MODEL,\n",
        "        system_instruction=system_message()\n",
        "    )\n",
        "    response = gemini.generate_content(\n",
        "        user_prompt(items),\n",
        "        stream=True\n",
        "    )\n",
        "    for chunk in response:\n",
        "        if chunk.text:\n",
        "            reply += chunk.text\n",
        "            yield reply.replace('```python\\n','').replace('```','')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = [\n",
        "    {\"start\": \"00:01\", \"text\": \"ich habe ein buch gelesen\"},\n",
        "    {\"start\": \"00:05\", \"text\": \"dass ist ein haus\"},\n",
        "    {\"start\": \"00:10\", \"text\": \"wie geht es dir\"}\n",
        "]\n",
        "\n",
        "print(\"Calling stream_google with sample data...\")\n",
        "for chunk in stream_google(sample_data):\n",
        "    print(chunk)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QFT1R8wbFjq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdFGTJCL873e"
      },
      "outputs": [],
      "source": [
        "def optimize(python, model):\n",
        "    if model==\"GPT\":\n",
        "        result = stream_gpt(python)\n",
        "    elif model==\"Claude\":\n",
        "        result = stream_claude(python)\n",
        "    elif model==\"Gemini\":\n",
        "        result = stream_google(python)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model\")\n",
        "    for stream_so_far in result:\n",
        "        yield stream_so_far"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxw2O_xQ873e"
      },
      "outputs": [],
      "source": [
        "def execute_python(code):\n",
        "        try:\n",
        "            output = io.StringIO()\n",
        "            sys.stdout = output\n",
        "            exec(code)\n",
        "        finally:\n",
        "            sys.stdout = sys.__stdout__\n",
        "        return output.getvalue()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3ReogCUGEsu"
      },
      "outputs": [],
      "source": [
        "from gradio.components import html\n",
        "from gradio.utils import T\n",
        "\"\"\"Gradio UI for the YouTube Transcript Utility.\"\"\"\n",
        "\n",
        "from typing import List, Dict, Union, Tuple\n",
        "import gradio as gr\n",
        "\n",
        "css: str = \"\"\"\n",
        "  #my_html_box { border: 2px solid blue; padding: 10px; }\n",
        "\"\"\"\n",
        "\n",
        "js: str  = \"\"\"\n",
        "function() {\n",
        "    const table = document.querySelector('table');\n",
        "    const range = document.createRange();\n",
        "    range.selectNode(table);\n",
        "    window.getSelection().removeAllRanges();\n",
        "    window.getSelection().addRange(range);\n",
        "    document.execCommand('copy');\n",
        "    alert('Table copied to clipboard!');\n",
        "    window.getSelection().removeAllRanges();\n",
        "    return [];\n",
        "    }\n",
        "\"\"\"\n",
        "\n",
        "sample_url: str = 'https://www.youtube.com/watch?v=L6HnBjnkKmM&list=PLCCi8icw2DAO1qZGH7heUyTB8bJP1ICZ5&index=28'\n",
        "\n",
        "def clear_fields() -> Tuple[None, str, str]:\n",
        "    return (None, \"\", \"\")\n",
        "\n",
        "def mock_original_data(url: str) -> List[Dict[str, str]]:\n",
        "    return [\n",
        "      {\"start\": \"00:01\", \"text\": \"ich habe ein buch gelesen\"},\n",
        "      {\"start\": \"00:05\", \"text\": \"dass ist ein haus\"},\n",
        "      {\"start\": \"00:10\", \"text\": \"wie geht es dir\"}\n",
        "    ]\n",
        "\n",
        "def mock_modified_data(url: str) -> List[Dict[str, str]]:\n",
        "    return [\n",
        "      {\"start\": \"00:01\", \"text\": \"Ich habe ein Buch gelesen.\"},\n",
        "      {\"start\": \"00:05\", \"text\": \"Das ist ein Haus.\"},\n",
        "      {\"start\": \"00:10\", \"text\": \"Wie geht es dir?\"}\n",
        "    ]\n",
        "\n",
        "def build_table(items: List[Dict[str, str]]) -> str:\n",
        "    html: str = \"<table width=100%>\\n\"\n",
        "    html += \"  <tbody>\\n\"\n",
        "    for item in items:\n",
        "        html += f\"    <tr><td>{item['start']}</td><td>{item['text']}</td></tr>\\n\"\n",
        "    html += \"  </tbody>\\n\"\n",
        "    html += \"</table>\"\n",
        "    return html\n",
        "\n",
        "def build_text(items: List[Dict[str, str]]) -> str:\n",
        "    return str(items)\n",
        "\n",
        "def fetch_transcript(url: str, mock: bool, model: str) -> Tuple[str, str]:\n",
        "    if not url:\n",
        "        return \"\", \"<p style='color: orange;'>The YouTube Video URL field can't be empty!</p>\"\n",
        "    else:\n",
        "        transcript_original: List[Dict[str, str]] = mock_original_data(url) if mock else utilities.get_transcript(url)\n",
        "        transcript_modified = mock_modified_data(url) # if mock else stuff here\n",
        "        list_original: str = build_text(transcript_original)\n",
        "        html_modified: str = build_table(transcript_modified)\n",
        "        return list_original, html_modified\n",
        "\n",
        "with gr.Blocks(css=css) as ui:\n",
        "\n",
        "    gr.Markdown(\"## YouTube Transcript Utility\")\n",
        "    gr.Markdown(\"### Creates a HTML table that can be copied and pasted into a Windows OneNote application\")\n",
        "\n",
        "    with gr.Row():\n",
        "        url = gr.Textbox(label=\"YouTube Video URL:\", value=sample_url)\n",
        "    with gr.Row():\n",
        "        model = gr.Dropdown([\"GPT\", \"Claude\", \"Gemini\"], label=\"AI Model Name:\", value=\"GPT\")\n",
        "    with gr.Row():\n",
        "        mock = gr.Checkbox(label=\"Use Mock Data\", value=True)\n",
        "    with gr.Row():\n",
        "        fetch = gr.Button(\"Fetch\", variant=\"primary\")\n",
        "        copy = gr.Button(\"Copy\")\n",
        "        clear = gr.Button(\"Clear\")\n",
        "    with gr.Row():\n",
        "        text_original = gr.TextArea(label=\"Original Transcript\")\n",
        "        html_modified = gr.HTML(elem_id=\"my_html_box\")\n",
        "\n",
        "    fetch.click(fetch_transcript, inputs=[url, mock, model], outputs=[text_original, html_modified])\n",
        "    copy.click(fn=None, inputs=[], outputs=[], js=js)\n",
        "    clear.click(clear_fields, inputs=[], outputs=[url, text_original, html_modified])\n",
        "\n",
        "ui.launch(inbrowser=True, debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "ai-llm-youtube-transcription-utility",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}